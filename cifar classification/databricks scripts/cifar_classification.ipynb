{"cells":[{"cell_type":"code","source":["configs = {\n  \"fs.adl.oauth2.access.token.provider.type\": \"ClientCredential\",\n  \"fs.adl.oauth2.client.id\": \"4ab956bb-5a0b-45b3-a87b-22424b89ea36\",\n  \"fs.adl.oauth2.credential\": \".2SD44SJ2nti=QtOym[@anQ[cXiW?6v.\",\n  \"fs.adl.oauth2.refresh.url\": \"https://login.microsoftonline.com/5d7e4366-1b9b-45cf-8e79-b14b27df46e1/oauth2/token\"}\n\ndbutils.fs.mount(\n  source = \"adl://imagerepo.azuredatalakestore.net/dogImages\",\n  mount_point  = \"/mnt/dogImages\",\n  extra_configs = configs)\n\ndbutils.fs.mount(\n  source = \"adl://imagerepo.azuredatalakestore.net/cifar-10-batches-py\",\n  mount_point  = \"/mnt/cifar-10-batches-py\",\n  extra_configs = configs)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ExecutionError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-949048213614856&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      8</span>   source <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;adl://imagerepo.azuredatalakestore.net/dogImages&#34;</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      9</span>   mount_point  <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;/mnt/dogImages&#34;</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">---&gt; 10</span><span class=\"ansi-red-fg\">   extra_configs = configs)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">     11</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     12</span> dbutils.fs.mount(\n\n<span class=\"ansi-green-fg\">/local_disk0/tmp/1587916602159-0/dbutils.py</span> in <span class=\"ansi-cyan-fg\">f_with_exception_handling</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    312</span>                     exc<span class=\"ansi-blue-fg\">.</span>__context__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    313</span>                     exc<span class=\"ansi-blue-fg\">.</span>__cause__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-fg\">--&gt; 314</span><span class=\"ansi-red-fg\">                     </span><span class=\"ansi-green-fg\">raise</span> exc\n<span class=\"ansi-green-intense-fg ansi-bold\">    315</span>             <span class=\"ansi-green-fg\">return</span> f_with_exception_handling\n<span class=\"ansi-green-intense-fg ansi-bold\">    316</span> \n\n<span class=\"ansi-red-fg\">ExecutionError</span>: An error occurred while calling o222.mount.\n: java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/dogImages; nested exception is: \n\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/dogImages\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:123)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:63)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:465)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/dogImages\n\tat scala.Predef$.require(Predef.scala:281)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:224)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:326)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:220)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:79)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:103)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:102)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:102)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$3.applyOrElse(DbfsServerBackend.scala:304)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$3.applyOrElse(DbfsServerBackend.scala:282)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$2(ServerBackend.scala:52)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:79)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:79)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:48)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$4(UsageLogging.scala:428)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:238)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:233)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:230)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:15)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:275)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:268)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:15)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:409)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:336)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:15)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:47)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleRPC$2(JettyServer.scala:611)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:611)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:534)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$4(JettyServer.scala:321)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:238)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:233)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:230)\n\tat com.databricks.rpc.JettyServer$.withAttributionContext(JettyServer.scala:152)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:275)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:268)\n\tat com.databricks.rpc.JettyServer$.withAttributionTags(JettyServer.scala:152)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:310)\n\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:217)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:539)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\n\tat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\n\t... 1 more\n</div>"]}}],"execution_count":1},{"cell_type":"code","source":["def unpickle(file):\n    import pickle\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["[str(name).upper() for name in unpickle(\"/dbfs/mnt/cifar-10-batches-py/batches.meta\")[b'label_names']]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[2]: [&#34;B&#39;AIRPLANE&#39;&#34;,\n &#34;B&#39;AUTOMOBILE&#39;&#34;,\n &#34;B&#39;BIRD&#39;&#34;,\n &#34;B&#39;CAT&#39;&#34;,\n &#34;B&#39;DEER&#39;&#34;,\n &#34;B&#39;DOG&#39;&#34;,\n &#34;B&#39;FROG&#39;&#34;,\n &#34;B&#39;HORSE&#39;&#34;,\n &#34;B&#39;SHIP&#39;&#34;,\n &#34;B&#39;TRUCK&#39;&#34;]</div>"]}}],"execution_count":3},{"cell_type":"code","source":["import numpy as np\nfrom keras.utils import np_utils\n# prepare data\nclassfication_names = unpickle(\"/dbfs/mnt/cifar-10-batches-py/batches.meta\")[b'label_names']\ntest_data = unpickle(\"/dbfs/mnt/cifar-10-batches-py/test_batch\")\ntest_tensors = np.array([np.moveaxis(test_data[b'data'][i].reshape(-1,32,32), 0, -1) for i in range(test_data[b'data'].shape[0])])\ntest_targets = np_utils.to_categorical(np.array(test_data[b'labels']), 20)\n\ntrain_data = unpickle(\"/dbfs/mnt/cifar-10-batches-py/data_batch_5\")\nvalid_tensors = np.array([np.moveaxis(train_data[b'data'][i].reshape(-1,32,32), 0, -1) for i in range(train_data[b'data'].shape[0])])\nvalid_targets = np_utils.to_categorical(np.array(train_data[b'labels']), 10)\ntrain_tensors = valid_tensors\ntrain_targets = valid_targets\nfor i in range(1,5):\n  train_data = unpickle(\"/dbfs/mnt/cifar-10-batches-py/data_batch_\" + str(i))\n  tensors = np.array([np.moveaxis(train_data[b'data'][i].reshape(-1,32,32), 0, -1) for i in range(train_data[b'data'].shape[0])])\n  targets = np_utils.to_categorical(np.array(train_data[b'labels']), 10)\n  train_tensors = np.concatenate((train_tensors, tensors), axis=0)\n  train_targets = np.concatenate((train_targets, targets), axis=0)\ntrain_tensors = train_tensors[10000:]\ntrain_targets = train_targets[10000:]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Using TensorFlow backend.\n/databricks/python/lib/python3.7/site-packages/botocore/vendored/requests/packages/urllib3/_collections.py:1: DeprecationWarning: Using or importing the ABCs from &#39;collections&#39; instead of from &#39;collections.abc&#39; is deprecated, and in 3.8 it will stop working\n  from collections import Mapping, MutableMapping\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["def extract_VGG16(tensor):\n\tfrom keras.applications.vgg16 import VGG16, preprocess_input\n\treturn VGG16(weights='imagenet', include_top=False).predict(preprocess_input(tensor))\n\ndef extract_VGG19(tensor):\n\tfrom keras.applications.vgg19 import VGG19, preprocess_input\n\treturn VGG19(weights='imagenet', include_top=False).predict(preprocess_input(tensor))\n\ndef extract_Resnet50(tensor):\n\tfrom keras.applications.resnet50 import ResNet50, preprocess_input\n\treturn ResNet50(weights='imagenet', include_top=False).predict(preprocess_input(tensor))\n\ndef extract_Xception(tensor):\n\tfrom keras.applications.xception import Xception, preprocess_input\n\treturn Xception(weights='imagenet', include_top=False).predict(preprocess_input(tensor))\n\ndef extract_InceptionV3(tensor):\n\tfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\n\treturn InceptionV3(weights='imagenet', include_top=False).predict(preprocess_input(tensor))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["train_ResNet50 = extract_Resnet50(train_tensors)\nvalid_ResNet50 = extract_Resnet50(valid_tensors)\ntest_ResNet50 = extract_Resnet50(test_tensors)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">WARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n\n/databricks/python/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n  warnings.warn(&#39;The output shape of `ResNet50(include_top=False)` &#39;\nDownloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\n    8192/94653016 [..............................] - ETA: 3s\n 2990080/94653016 [..............................] - ETA: 1s\n11436032/94653016 [==&gt;...........................] - ETA: 0s\n16515072/94653016 [====&gt;.........................] - ETA: 0s\n21536768/94653016 [=====&gt;........................] - ETA: 0s\n26607616/94653016 [=======&gt;......................] - ETA: 0s\n31719424/94653016 [=========&gt;....................] - ETA: 0s\n36741120/94653016 [==========&gt;...................] - ETA: 0s\n41623552/94653016 [============&gt;.................] - ETA: 0s\n47144960/94653016 [=============&gt;................] - ETA: 0s\n52125696/94653016 [===============&gt;..............] - ETA: 0s\n57204736/94653016 [=================&gt;............] - ETA: 0s\n62210048/94653016 [==================&gt;...........] - ETA: 0s\n67280896/94653016 [====================&gt;.........] - ETA: 0s\n72294400/94653016 [=====================&gt;........] - ETA: 0s\n77307904/94653016 [=======================&gt;......] - ETA: 0s\n82370560/94653016 [=========================&gt;....] - ETA: 0s\n87416832/94653016 [==========================&gt;...] - ETA: 0s\n92405760/94653016 [============================&gt;.] - ETA: 0s\n94658560/94653016 [==============================] - 1s 0us/step\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Conv1D\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.models import Sequential\n\nmy_ResNet50_model = Sequential()\n# my_ResNet50_model.add(GlobalAveragePooling2D(input_shape=train_ResNet50.shape[1:]))\nmy_ResNet50_model.add(Dense(32, input_shape=train_ResNet50.shape[1:], activation='relu'))\nmy_ResNet50_model.add(Flatten())\nmy_ResNet50_model.add(Dense(10, activation='softmax'))\n\nmy_ResNet50_model.summary()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">WARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n\nModel: &#34;sequential_1&#34;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 1, 1, 32)          65568     \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 32)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                330       \n=================================================================\nTotal params: 65,898\nTrainable params: 65,898\nNon-trainable params: 0\n_________________________________________________________________\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["my_ResNet50_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">WARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["from keras.callbacks import ModelCheckpoint\n\n\ncheckpointer = ModelCheckpoint(filepath='weights.best.CifarResNet-50.hdf5', \n                               verbose=1, save_best_only=True)\n\nmy_ResNet50_model.fit(train_ResNet50, train_targets, \n          validation_data=(valid_ResNet50, valid_targets),\n          epochs=20, batch_size=50, callbacks=[checkpointer], verbose=1)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">WARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n\nTrain on 40000 samples, validate on 10000 samples\nEpoch 1/20\n\n   50/40000 [..............................] - ETA: 35:33 - loss: 3.9338 - acc: 0.0800\n  900/40000 [..............................] - ETA: 1:58 - loss: 2.3553 - acc: 0.2922 \n 1750/40000 [&gt;.............................] - ETA: 1:00 - loss: 2.0809 - acc: 0.3417\n 2650/40000 [&gt;.............................] - ETA: 39s - loss: 1.9343 - acc: 0.3785 \n 3500/40000 [=&gt;............................] - ETA: 30s - loss: 1.8654 - acc: 0.3926\n 4350/40000 [==&gt;...........................] - ETA: 24s - loss: 1.8115 - acc: 0.4032\n 5150/40000 [==&gt;...........................] - ETA: 20s - loss: 1.7505 - acc: 0.4231\n 6050/40000 [===&gt;..........................] - ETA: 17s - loss: 1.7127 - acc: 0.4322\n 6950/40000 [====&gt;.........................] - ETA: 14s - loss: 1.6661 - acc: 0.4455\n 7850/40000 [====&gt;.........................] - ETA: 12s - loss: 1.6362 - acc: 0.4581\n 8750/40000 [=====&gt;........................] - ETA: 11s - loss: 1.6089 - acc: 0.4685\n 9400/40000 [======&gt;.......................] - ETA: 10s - loss: 1.5890 - acc: 0.4760\n10250/40000 [======&gt;.......................] - ETA: 9s - loss: 1.5665 - acc: 0.4828 \n11050/40000 [=======&gt;......................] - ETA: 8s - loss: 1.5523 - acc: 0.4878\n11950/40000 [=======&gt;......................] - ETA: 7s - loss: 1.5363 - acc: 0.4935\n12850/40000 [========&gt;.....................] - ETA: 7s - loss: 1.5219 - acc: 0.4982\n13750/40000 [=========&gt;....................] - ETA: 6s - loss: 1.5074 - acc: 0.5026\n14650/40000 [=========&gt;....................] - ETA: 6s - loss: 1.4920 - acc: 0.5068\n15550/40000 [==========&gt;...................] - ETA: 5s - loss: 1.4773 - acc: 0.5116\n16450/40000 [===========&gt;..................] - ETA: 5s - loss: 1.4661 - acc: 0.5152\n17250/40000 [===========&gt;..................] - ETA: 4s - loss: 1.4546 - acc: 0.5182\n18000/40000 [============&gt;.................] - ETA: 4s - loss: 1.4452 - acc: 0.5206\n18750/40000 [=============&gt;................] - ETA: 4s - loss: 1.4373 - acc: 0.5228\n19600/40000 [=============&gt;................] - ETA: 4s - loss: 1.4251 - acc: 0.5268\n20500/40000 [==============&gt;...............] - ETA: 3s - loss: 1.4157 - acc: 0.5297\n21400/40000 [===============&gt;..............] - ETA: 3s - loss: 1.4068 - acc: 0.5323\n22300/40000 [===============&gt;..............] - ETA: 3s - loss: 1.3981 - acc: 0.5355\n23200/40000 [================&gt;.............] - ETA: 2s - loss: 1.3893 - acc: 0.5383\n24000/40000 [=================&gt;............] - ETA: 2s - loss: 1.3826 - acc: 0.5401\n24900/40000 [=================&gt;............] - ETA: 2s - loss: 1.3776 - acc: 0.5416\n25800/40000 [==================&gt;...........] - ETA: 2s - loss: 1.3705 - acc: 0.5447\n26700/40000 [===================&gt;..........] - ETA: 2s - loss: 1.3645 - acc: 0.5462\n27650/40000 [===================&gt;..........] - ETA: 1s - loss: 1.3552 - acc: 0.5484\n28500/40000 [====================&gt;.........] - ETA: 1s - loss: 1.3503 - acc: 0.5499\n29400/40000 [=====================&gt;........] - ETA: 1s - loss: 1.3464 - acc: 0.5511\n30300/40000 [=====================&gt;........] - ETA: 1s - loss: 1.3387 - acc: 0.5536\n31200/40000 [======================&gt;.......] - ETA: 1s - loss: 1.3352 - acc: 0.5553\n31850/40000 [======================&gt;.......] - ETA: 1s - loss: 1.3324 - acc: 0.5560\n32800/40000 [=======================&gt;......] - ETA: 1s - loss: 1.3283 - acc: 0.5580\n33700/40000 [========================&gt;.....] - ETA: 0s - loss: 1.3229 - acc: 0.5605\n34650/40000 [========================&gt;.....] - ETA: 0s - loss: 1.3177 - acc: 0.5618\n35450/40000 [=========================&gt;....] - ETA: 0s - loss: 1.3127 - acc: 0.5634\n36400/40000 [==========================&gt;...] - ETA: 0s - loss: 1.3049 - acc: 0.5655\n37250/40000 [==========================&gt;...] - ETA: 0s - loss: 1.3009 - acc: 0.5667\n38000/40000 [===========================&gt;..] - ETA: 0s - loss: 1.2992 - acc: 0.5672\n38950/40000 [============================&gt;.] - ETA: 0s - loss: 1.2945 - acc: 0.5681\n39850/40000 [============================&gt;.] - ETA: 0s - loss: 1.2890 - acc: 0.5696\n40000/40000 [==============================] - 6s 149us/step - loss: 1.2881 - acc: 0.5700 - val_loss: 1.1075 - val_acc: 0.6227\n\nEpoch 00001: val_loss improved from inf to 1.10749, saving model to weights.best.CifarResNet-50.hdf5\nEpoch 2/20\n\n   50/40000 [..............................] - ETA: 5s - loss: 0.6788 - acc: 0.6800\n  950/40000 [..............................] - ETA: 2s - loss: 0.9568 - acc: 0.6516\n 1750/40000 [&gt;.............................] - ETA: 2s - loss: 0.9332 - acc: 0.6606\n 2700/40000 [=&gt;............................] - ETA: 2s - loss: 0.9669 - acc: 0.6526\n 3600/40000 [=&gt;............................] - ETA: 2s - loss: 0.9767 - acc: 0.6536\n 4550/40000 [==&gt;...........................] - ETA: 2s - loss: 0.9746 - acc: 0.6567\n 5450/40000 [===&gt;..........................] - ETA: 2s - loss: 0.9875 - acc: 0.6563\n 6050/40000 [===&gt;..........................] - ETA: 2s - loss: 0.9884 - acc: 0.6560\n 6950/40000 [====&gt;.........................] - ETA: 1s - loss: 0.9940 - acc: 0.6534\n 7800/40000 [====&gt;.........................] - ETA: 1s - loss: 0.9905 - acc: 0.6540\n 8750/40000 [=====&gt;........................] - ETA: 1s - loss: 0.9904 - acc: 0.6537\n 9650/40000 [======&gt;.......................] - ETA: 1s - loss: 0.9952 - acc: 0.6527\n10550/40000 [======&gt;.......................] - ETA: 1s - loss: 0.9978 - acc: 0.6514\n11450/40000 [=======&gt;......................] - ETA: 1s - loss: 1.0006 - acc: 0.6520\n12350/40000 [========&gt;.....................] - ETA: 1s - loss: 0.9972 - acc: 0.6540\n13300/40000 [========&gt;.....................] - ETA: 1s - loss: 0.9988 - acc: 0.6541\n14200/40000 [=========&gt;....................] - ETA: 1s - loss: 1.0008 - acc: 0.6544\n15000/40000 [==========&gt;...................] - ETA: 1s - loss: 0.9980 - acc: 0.6548\n15900/40000 [==========&gt;...................] - ETA: 1s - loss: 0.9976 - acc: 0.6553\n16700/40000 [===========&gt;..................] - ETA: 1s - loss: 0.9981 - acc: 0.6550\n17550/40000 [============&gt;.................] - ETA: 1s - loss: 0.9986 - acc: 0.6552\n18400/40000 [============&gt;.................] - ETA: 1s - loss: 1.0002 - acc: 0.6557\n19250/40000 [=============&gt;................] - ETA: 1s - loss: 1.0008 - acc: 0.6552\n20050/40000 [==============&gt;...............] - ETA: 1s - loss: 0.9990 - acc: 0.6556\n20950/40000 [==============&gt;...............] - ETA: 1s - loss: 0.9976 - acc: 0.6562\n21850/40000 [===============&gt;..............] - ETA: 1s - loss: 0.9981 - acc: 0.6557\n22500/40000 [===============&gt;..............] - ETA: 1s - loss: 0.9985 - acc: 0.6558\n23200/40000 [================&gt;.............] - ETA: 1s - loss: 0.9983 - acc: 0.6558\n24100/40000 [=================&gt;............] - ETA: 0s - loss: 0.9964 - acc: 0.6568\n25050/40000 [=================&gt;............] - ETA: 0s - loss: 0.9946 - acc: 0.6570\n25850/40000 [==================&gt;...........] - ETA: 0s - loss: 0.9935 - acc: 0.6576\n26750/40000 [===================&gt;..........] - ETA: 0s - loss: 0.9941 - acc: 0.6578\n27600/40000 [===================&gt;..........] - ETA: 0s - loss: 0.9927 - acc: 0.6585\n28350/40000 [====================&gt;.........] - ETA: 0s - loss: 0.9937 - acc: 0.6584\n29000/40000 [====================&gt;.........] - ETA: 0s - loss: 0.9934 - acc: 0.6586\n29900/40000 [=====================&gt;........] - ETA: 0s - loss: 0.9947 - acc: 0.6586\n30700/40000 [======================&gt;.......] - ETA: 0s - loss: 0.9975 - acc: 0.6577\n31550/40000 [======================&gt;.......] - ETA: 0s - loss: 0.9972 - acc: 0.6578\n32400/40000 [=======================&gt;......] - ETA: 0s - loss: 0.9966 - acc: 0.6576\n33200/40000 [=======================&gt;......] - ETA: 0s - loss: 0.9982 - acc: 0.6573\n34150/40000 [========================&gt;.....] - ETA: 0s - loss: 0.9982 - acc: 0.6578\n35100/40000 [=========================&gt;....] - ETA: 0s - loss: 0.9998 - acc: 0.6575\n36000/40000 [==========================&gt;...] - ETA: 0s - loss: 1.0006 - acc: 0.6572\n36950/40000 [==========================&gt;...] - ETA: 0s - loss: 1.0023 - acc: 0.6563\n37850/40000 [===========================&gt;..] - ETA: 0s - loss: 1.0033 - acc: 0.6561\n38650/40000 [===========================&gt;..] - ETA: 0s - loss: 1.0029 - acc: 0.6561\n39450/40000 [============================&gt;.] - ETA: 0s - loss: 1.0028 - acc: 0.6562\n40000/40000 [==============================] - 3s 70us/step - loss: 1.0021 - acc: 0.6566 - val_loss: 1.0834 - val_acc: 0.6413\n\nEpoch 00002: val_loss improved from 1.10749 to 1.08342, saving model to weights.best.CifarResNet-50.hdf5\nEpoch 3/20\n\n   50/40000 [..............................] - ETA: 3s - loss: 0.8855 - acc: 0.7000\n  600/40000 [..............................] - ETA: 3s - loss: 0.9204 - acc: 0.6900\n 1500/40000 [&gt;.............................] - ETA: 2s - loss: 0.8719 - acc: 0.7033\n 2400/40000 [&gt;.............................] - ETA: 2s - loss: 0.8889 - acc: 0.6904\n 3300/40000 [=&gt;............................] - ETA: 2s - loss: 0.8789 - acc: 0.6945\n 4250/40000 [==&gt;...........................] - ETA: 2s - loss: 0.8844 - acc: 0.6929\n 5150/40000 [==&gt;...........................] - ETA: 2s - loss: 0.8912 - acc: 0.6897\n 6050/40000 [===&gt;..........................] - ETA: 2s - loss: 0.8996 - acc: 0.6878\n 6950/40000 [====&gt;.........................] - ETA: 1s - loss: 0.9026 - acc: 0.6862\n 7900/40000 [====&gt;.........................] - ETA: 1s - loss: 0.9018 - acc: 0.6862\n 8800/40000 [=====&gt;........................] - ETA: 1s - loss: 0.8927 - acc: 0.6883\n 9700/40000 [======&gt;.......................] - ETA: 1s - loss: 0.8947 - acc: 0.6885\n10650/40000 [======&gt;.......................] - ETA: 1s - loss: 0.9001 - acc: 0.6879\n11550/40000 [=======&gt;......................] - ETA: 1s - loss: 0.9032 - acc: 0.6859\n12500/40000 [========&gt;.....................] - ETA: 1s - loss: 0.9006 - acc: 0.6877\n13450/40000 [=========&gt;....................] - ETA: 1s - loss: 0.9036 - acc: 0.6861\n14400/40000 [=========&gt;....................] - ETA: 1s - loss: 0.9058 - acc: 0.6856\n15100/40000 [==========&gt;...................] - ETA: 1s - loss: 0.9071 - acc: 0.6850\n16000/40000 [===========&gt;..................] - ETA: 1s - loss: 0.9062 - acc: 0.6844\n16950/40000 [===========&gt;..................] - ETA: 1s - loss: 0.9070 - acc: 0.6847\n17800/40000 [============&gt;.................] - ETA: 1s - loss: 0.9048 - acc: 0.6857\n18650/40000 [============&gt;.................] - ETA: 1s - loss: 0.9043 - acc: 0.6862\n19550/40000 [=============&gt;................] - ETA: 1s - loss: 0.9028 - acc: 0.6863\n20500/40000 [==============&gt;...............] - ETA: 1s - loss: 0.9012 - acc: 0.6873\n21400/40000 [===============&gt;..............] - ETA: 1s - loss: 0.9051 - acc: 0.6860\n22150/40000 [===============&gt;..............] - ETA: 1s - loss: 0.9050 - acc: 0.6862\n22950/40000 [================&gt;.............] - ETA: 1s - loss: 0.9047 - acc: 0.6863\n23850/40000 [================&gt;.............] - ETA: 0s - loss: 0.9050 - acc: 0.6862\n24600/40000 [=================&gt;............] - ETA: 0s - loss: 0.9050 - acc: 0.6864\n25400/40000 [==================&gt;...........] - ETA: 0s - loss: 0.9061 - acc: 0.6866\n26050/40000 [==================&gt;...........] - ETA: 0s - loss: 0.9068 - acc: 0.6868\n26800/40000 [===================&gt;..........] - ETA: 0s - loss: 0.9058 - acc: 0.6875\n27650/40000 [===================&gt;..........] - ETA: 0s - loss: 0.9059 - acc: 0.6874\n28450/40000 [====================&gt;.........] - ETA: 0s - loss: 0.9071 - acc: 0.6871\n29350/40000 [=====================&gt;........] - ETA: 0s - loss: 0.9069 - acc: 0.6876\n30250/40000 [=====================&gt;........] - ETA: 0s - loss: 0.9075 - acc: 0.6877\n31100/40000 [======================&gt;.......] - ETA: 0s - loss: 0.9064 - acc: 0.6883\n31900/40000 [======================&gt;.......] - ETA: 0s - loss: 0.9060 - acc: 0.6886\n32800/40000 [=======================&gt;......] - ETA: 0s - loss: 0.9048 - acc: 0.6885\n33650/40000 [========================&gt;.....] - ETA: 0s - loss: 0.9053 - acc: 0.6884\n34500/40000 [========================&gt;.....] - ETA: 0s - loss: 0.9048 - acc: 0.6885\n35400/40000 [=========================&gt;....] - ETA: 0s - loss: 0.9062 - acc: 0.6883\n35950/40000 [=========================&gt;....] - ETA: 0s - loss: 0.9053 - acc: 0.6892\n36850/40000 [==========================&gt;...] - ETA: 0s - loss: 0.9042 - acc: 0.6891\n37750/40000 [===========================&gt;..] - ETA: 0s - loss: 0.9060 - acc: 0.6886\n38650/40000 [===========================&gt;..] - ETA: 0s - loss: 0.9079 - acc: 0.6881\n39300/40000 [============================&gt;.] - ETA: 0s - loss: 0.9086 - acc: 0.6879\n40000/40000 [==============================] - 3s 71us/step - loss: 0.9079 - acc: 0.6883 - val_loss: 1.0695 - val_acc: 0.6473\n\nEpoch 00003: val_loss improved from 1.08342 to 1.06947, saving model to weights.best.CifarResNet-50.hdf5\nEpoch 4/20\n\n   50/40000 [..............................] - ETA: 3s - loss: 0.5702 - acc: 0.7600\n  900/40000 [..............................] - ETA: 2s - loss: 0.7810 - acc: 0.7267\n 1800/40000 [&gt;.............................] - ETA: 2s - loss: 0.7885 - acc: 0.7294\n 2600/40000 [&gt;.............................] - ETA: 2s - loss: 0.7956 - acc: 0.7242\n 3350/40000 [=&gt;............................] - ETA: 2s - loss: 0.8099 - acc: 0.7230\n 4150/40000 [==&gt;...........................] - ETA: 2s - loss: 0.8002 - acc: 0.7263\n 5050/40000 [==&gt;...........................] - ETA: 2s - loss: 0.7926 - acc: 0.7277\n 6000/40000 [===&gt;..........................] - ETA: 2s - loss: 0.8023 - acc: 0.7247\n 6750/40000 [====&gt;.........................] - ETA: 2s - loss: 0.8000 - acc: 0.7281\n 7650/40000 [====&gt;.........................] - ETA: 1s - loss: 0.7998 - acc: 0.7268\n 8550/40000 [=====&gt;........................] - ETA: 1s - loss: 0.8022 - acc: 0.7247\n 9400/40000 [======&gt;.......................] - ETA: 1s - loss: 0.8103 - acc: 0.7218\n10300/40000 [======&gt;.......................] - ETA: 1s - loss: 0.8067 - acc: 0.7224\n11250/40000 [=======&gt;......................] - ETA: 1s - loss: 0.8062 - acc: 0.7220\n11800/40000 [=======&gt;......................] - ETA: 1s - loss: 0.8038 - acc: 0.7228\n12700/40000 [========&gt;.....................] - ETA: 1s - loss: 0.8111 - acc: 0.7209\n13600/40000 [=========&gt;....................] - ETA: 1s - loss: 0.8127 - acc: 0.7202\n14550/40000 [=========&gt;....................] - ETA: 1s - loss: 0.8190 - acc: 0.7180\n15250/40000 [==========&gt;...................] - ETA: 1s - loss: 0.8220 - acc: 0.7163\n16100/40000 [===========&gt;..................] - ETA: 1s - loss: 0.8237 - acc: 0.7159\n17000/40000 [===========&gt;..................] - ETA: 1s - loss: 0.8263 - acc: 0.7135\n17900/40000 [============&gt;.................] - ETA: 1s - loss: 0.8268 - acc: 0.7133\n18800/40000 [=============&gt;................] - ETA: 1s - loss: 0.8265 - acc: 0.7132\n19500/40000 [=============&gt;................] - ETA: 1s - loss: 0.8251 - acc: 0.7139\n20350/40000 [==============&gt;...............] - ETA: 1s - loss: 0.8276 - acc: 0.7140\n21250/40000 [==============&gt;...............] - ETA: 1s - loss: 0.8305 - acc: 0.7137\n22150/40000 [===============&gt;..............] - ETA: 1s - loss: 0.8311 - acc: 0.7130\n23000/40000 [================&gt;.............] - ETA: 1s - loss: 0.8319 - acc: 0.7124\n23850/40000 [================&gt;.............] - ETA: 0s - loss: 0.8332 - acc: 0.7117\n24750/40000 [=================&gt;............] - ETA: 0s - loss: 0.8347 - acc: 0.7111\n25400/40000 [==================&gt;...........] - ETA: 0s - loss: 0.8342 - acc: 0.7114\n26300/40000 [==================&gt;...........] - ETA: 0s - loss: 0.8359 - acc: 0.7111\n27100/40000 [===================&gt;..........] - ETA: 0s - loss: 0.8370 - acc: 0.7103\n27800/40000 [===================&gt;..........] - ETA: 0s - loss: 0.8373 - acc: 0.7103\n28400/40000 [====================&gt;.........] - ETA: 0s - loss: 0.8361 - acc: 0.7109\n29200/40000 [====================&gt;.........] - ETA: 0s - loss: 0.8377 - acc: 0.7109\n29900/40000 [=====================&gt;........] - ETA: 0s - loss: 0.8395 - acc: 0.7100\n30750/40000 [======================&gt;.......] - ETA: 0s - loss: 0.8396 - acc: 0.7099\n31650/40000 [======================&gt;.......] - ETA: 0s - loss: 0.8409 - acc: 0.7095\n32500/40000 [=======================&gt;......] - ETA: 0s - loss: 0.8436 - acc: 0.7089\n33350/40000 [========================&gt;.....] - ETA: 0s - loss: 0.8438 - acc: 0.7089\n34300/40000 [========================&gt;.....] - ETA: 0s - loss: 0.8441 - acc: 0.7086\n35250/40000 [=========================&gt;....] - ETA: 0s - loss: 0.8450 - acc: 0.7081\n36050/40000 [==========================&gt;...] - ETA: 0s - loss: 0.8434 - acc: 0.7090\n36600/40000 [==========================&gt;...] - ETA: 0s - loss: 0.8441 - acc: 0.7090\n37500/40000 [===========================&gt;..] - ETA: 0s - loss: 0.8461 - acc: 0.7085\n38450/40000 [===========================&gt;..] - ETA: 0s - loss: 0.8465 - acc: 0.7080\n39400/40000 [============================&gt;.] - ETA: 0s - loss: 0.8456 - acc: 0.7081\n40000/40000 [==============================] - 3s 72us/step - loss: 0.8460 - acc: 0.7081 - val_loss: 1.0753 - val_acc: 0.6545\n\nEpoch 00004: val_loss did not improve from 1.06947\nEpoch 5/20\n\n   50/40000 [..............................] - ETA: 3s - loss: 0.6542 - acc: 0.8600\n 1000/40000 [..............................] - ETA: 2s - loss: 0.7357 - acc: 0.7670\n 1900/40000 [&gt;.............................] - ETA: 2s - loss: 0.7359 - acc: 0.7547\n 2800/40000 [=&gt;............................] - ETA: 2s - loss: 0.7504 - acc: 0.7482\n 3550/40000 [=&gt;............................] - ETA: 2s - loss: 0.7502 - acc: 0.7482\n 4450/40000 [==&gt;...........................] - ETA: 2s - loss: 0.7585 - acc: 0.7427\n 5300/40000 [==&gt;...........................] - ETA: 2s - loss: 0.7641 - acc: 0.7406\n 6200/40000 [===&gt;..........................] - ETA: 1s - loss: 0.7694 - acc: 0.7382\n 7100/40000 [====&gt;.........................] - ETA: 1s - loss: 0.7749 - acc: 0.7366\n 8000/40000 [=====&gt;........................] - ETA: 1s - loss: 0.7746 - acc: 0.7355\n 8900/40000 [=====&gt;........................] - ETA: 1s - loss: 0.7711 - acc: 0.7381\n 9800/40000 [======&gt;.......................] - ETA: 1s - loss: 0.7721 - acc: 0.7373\n10550/40000 [======&gt;.......................] - ETA: 1s - loss: 0.7710 - acc: 0.7373\n11400/40000 [=======&gt;......................] - ETA: 1s - loss: 0.7678 - acc: 0.7381\n12150/40000 [========&gt;.....................] - ETA: 1s - loss: 0.7717 - acc: 0.7367\n13050/40000 [========&gt;.....................] - ETA: 1s - loss: 0.7684 - acc: 0.7382\n13900/40000 [=========&gt;....................] - ETA: 1s - loss: 0.7697 - acc: 0.7374\n14800/40000 [==========&gt;...................] - ETA: 1s - loss: 0.7719 - acc: 0.7366\n15550/40000 [==========&gt;...................] - ETA: 1s - loss: 0.7729 - acc: 0.7371\n16500/40000 [===========&gt;..................] - ETA: 1s - loss: 0.7731 - acc: 0.7375\n17450/40000 [============&gt;.................] - ETA: 1s - loss: 0.7753 - acc: 0.7363\n18400/40000 [============&gt;.................] - ETA: 1s - loss: 0.7793 - acc: 0.7349\n19200/40000 [=============&gt;................] - ETA: 1s - loss: 0.7793 - acc: 0.7346\n19950/40000 [=============&gt;................] - ETA: 1s - loss: 0.7802 - acc: 0.7343\n20900/40000 [==============&gt;...............] - ETA: 1s - loss: 0.7801 - acc: 0.7339\n21800/40000 [===============&gt;..............] - ETA: 1s - loss: 0.7811 - acc: 0.7333\n22550/40000 [===============&gt;..............] - ETA: 1s - loss: 0.7804 - acc: 0.7333\n23350/40000 [================&gt;.............] - ETA: 1s - loss: 0.7822 - acc: 0.7326\n24250/40000 [=================&gt;............] - ETA: 0s - loss: 0.7824 - acc: 0.7324\n25100/40000 [=================&gt;............] - ETA: 0s - loss: 0.7838 - acc: 0.7325\n26000/40000 [==================&gt;...........] - ETA: 0s - loss: 0.7853 - acc: 0.7320\n26900/40000 [===================&gt;..........] - ETA: 0s - loss: 0.7867 - acc: 0.7312\n27750/40000 [===================&gt;..........] - ETA: 0s - loss: 0.7881 - acc: 0.7301\n28650/40000 [====================&gt;.........] - ETA: 0s - loss: 0.7882 - acc: 0.7300\n29550/40000 [=====================&gt;........] - ETA: 0s - loss: 0.7909 - acc: 0.7291\n30450/40000 [=====================&gt;........] - ETA: 0s - loss: 0.7922 - acc: 0.7284\n31150/40000 [======================&gt;.......] - ETA: 0s - loss: 0.7922 - acc: 0.7289\n32100/40000 [=======================&gt;......] - ETA: 0s - loss: 0.7942 - acc: 0.7279\n32950/40000 [=======================&gt;......] - ETA: 0s - loss: 0.7958 - acc: 0.7276\n33800/40000 [========================&gt;.....] - ETA: 0s - loss: 0.7960 - acc: 0.7277\n34750/40000 [=========================&gt;....] - ETA: 0s - loss: 0.7960 - acc: 0.7275\n35700/40000 [=========================&gt;....] - ETA: 0s - loss: 0.7985 - acc: 0.7270\n36650/40000 [==========================&gt;...] - ETA: 0s - loss: 0.7988 - acc: 0.7264\n37600/40000 [===========================&gt;..] - ETA: 0s - loss: 0.7974 - acc: 0.7267\n38500/40000 [===========================&gt;..] - ETA: 0s - loss: 0.7982 - acc: 0.7267\n39150/40000 [============================&gt;.] - ETA: 0s - loss: 0.7974 - acc: 0.7267\n40000/40000 [==============================] - 3s 70us/step - loss: 0.7989 - acc: 0.7262 - val_loss: 1.1184 - val_acc: 0.6544\n\nEpoch 00005: val_loss did not improve from 1.06947\nEpoch 6/20\n\n   50/40000 [..............................] - ETA: 3s - loss: 0.8245 - acc: 0.7400\n  750/40000 [..............................] - ETA: 2s - loss: 0.7494 - acc: 0.7240\n 1400/40000 [&gt;.............................] - ETA: 3s - loss: 0.7425 - acc: 0.7379\n 2250/40000 [&gt;.............................] - ETA: 2s - loss: 0.7265 - acc: 0.7404\n 3150/40000 [=&gt;............................] - ETA: 2s - loss: 0.7304 - acc: 0.7406\n 4050/40000 [==&gt;...........................] - ETA: 2s - loss: 0.7339 - acc: 0.7415\n 4850/40000 [==&gt;...........................] - ETA: 2s - loss: 0.7300 - acc: 0.7429\n 5750/40000 [===&gt;..........................] - ETA: 2s - loss: 0.7379 - acc: 0.7414\n 6550/40000 [===&gt;..........................] - ETA: 2s - loss: 0.7411 - acc: 0.7437\n 7450/40000 [====&gt;.........................] - ETA: 2s - loss: 0.7322 - acc: 0.7448\n 8350/40000 [=====&gt;........................] - ETA: 2s - loss: 0.7403 - acc: 0.7428\n 9200/40000 [=====&gt;........................] - ETA: 1s - loss: 0.7381 - acc: 0.7436\n 9750/40000 [======&gt;.......................] - ETA: 1s - loss: 0.7444 - acc: 0.7416\n10650/40000 [======&gt;.......................] - ETA: 1s - loss: 0.7429 - acc: 0.7413\n11550/40000 [=======&gt;......................] - ETA: 1s - loss: 0.7428 - acc: 0.7408\n12500/40000 [========&gt;.....................] - ETA: 1s - loss: 0.7445 - acc: 0.7406\n13450/40000 [=========&gt;....................] - ETA: 1s - loss: 0.7443 - acc: 0.7402\n14200/40000 [=========&gt;....................] - ETA: 1s - loss: 0.7444 - acc: 0.7411\n15150/40000 [==========&gt;...................] - ETA: 1s - loss: 0.7422 - acc: 0.7420\n16100/40000 [===========&gt;..................] - ETA: 1s - loss: 0.7438 - acc: 0.7411\n16800/40000 [===========&gt;..................] - ETA: 1s - loss: 0.7460 - acc: 0.7395\n17700/40000 [============&gt;.................] - ETA: 1s - loss: 0.7447 - acc: 0.7399\n18500/40000 [============&gt;.................] - ETA: 1s - loss: 0.7426 - acc: 0.7410\n19400/40000 [=============&gt;................] - ETA: 1s - loss: 0.7394 - acc: 0.7414\n20300/40000 [==============&gt;...............] - ETA: 1s - loss: 0.7401 - acc: 0.7414\n21200/40000 [==============&gt;...............] - ETA: 1s - loss: 0.7400 - acc: 0.7416\n22100/40000 [===============&gt;..............] - ETA: 1s - loss: 0.7415 - acc: 0.7414\n22950/40000 [================&gt;.............] - ETA: 1s - loss: 0.7448 - acc: 0.7405\n23900/40000 [================&gt;.............] - ETA: 0s - loss: 0.7468 - acc: 0.7390\n24800/40000 [=================&gt;............] - ETA: 0s - loss: 0.7470 - acc: 0.7391\n25600/40000 [==================&gt;...........] - ETA: 0s - loss: 0.7483 - acc: 0.7389\n26550/40000 [==================&gt;...........] - ETA: 0s - loss: 0.7493 - acc: 0.7389\n27450/40000 [===================&gt;..........] - ETA: 0s - loss: 0.7496 - acc: 0.7388\n28350/40000 [====================&gt;.........] - ETA: 0s - loss: 0.7502 - acc: 0.7390\n29300/40000 [====================&gt;.........] - ETA: 0s - loss: 0.7514 - acc: 0.7385\n30200/40000 [=====================&gt;........] - ETA: 0s - loss: 0.7526 - acc: 0.7380\n30950/40000 [======================&gt;.......] - ETA: 0s - loss: 0.7520 - acc: 0.7383\n31850/40000 [======================&gt;.......] - ETA: 0s - loss: 0.7528 - acc: 0.7384\n32800/40000 [=======================&gt;......] - ETA: 0s - loss: 0.7536 - acc: 0.7380\n33650/40000 [========================&gt;.....] - ETA: 0s - loss: 0.7550 - acc: 0.7374\n34500/40000 [========================&gt;.....] - ETA: 0s - loss: 0.7559 - acc: 0.7370\n\n*** WARNING: skipped 34644 bytes of output ***\n\n 5800/40000 [===&gt;..........................] - ETA: 2s - loss: 0.5036 - acc: 0.8267\n 6700/40000 [====&gt;.........................] - ETA: 2s - loss: 0.5067 - acc: 0.8282\n 7450/40000 [====&gt;.........................] - ETA: 2s - loss: 0.5017 - acc: 0.8291\n 8350/40000 [=====&gt;........................] - ETA: 1s - loss: 0.5057 - acc: 0.8273\n 9150/40000 [=====&gt;........................] - ETA: 1s - loss: 0.5089 - acc: 0.8263\n10000/40000 [======&gt;.......................] - ETA: 1s - loss: 0.5116 - acc: 0.8250\n10850/40000 [=======&gt;......................] - ETA: 1s - loss: 0.5127 - acc: 0.8249\n11700/40000 [=======&gt;......................] - ETA: 1s - loss: 0.5142 - acc: 0.8256\n12600/40000 [========&gt;.....................] - ETA: 1s - loss: 0.5111 - acc: 0.8268\n13500/40000 [=========&gt;....................] - ETA: 1s - loss: 0.5136 - acc: 0.8261\n14400/40000 [=========&gt;....................] - ETA: 1s - loss: 0.5167 - acc: 0.8253\n15300/40000 [==========&gt;...................] - ETA: 1s - loss: 0.5143 - acc: 0.8254\n16150/40000 [===========&gt;..................] - ETA: 1s - loss: 0.5165 - acc: 0.8250\n16950/40000 [===========&gt;..................] - ETA: 1s - loss: 0.5166 - acc: 0.8247\n17700/40000 [============&gt;.................] - ETA: 1s - loss: 0.5162 - acc: 0.8249\n18550/40000 [============&gt;.................] - ETA: 1s - loss: 0.5177 - acc: 0.8243\n19250/40000 [=============&gt;................] - ETA: 1s - loss: 0.5163 - acc: 0.8246\n20150/40000 [==============&gt;...............] - ETA: 1s - loss: 0.5159 - acc: 0.8241\n21050/40000 [==============&gt;...............] - ETA: 1s - loss: 0.5201 - acc: 0.8225\n21950/40000 [===============&gt;..............] - ETA: 1s - loss: 0.5208 - acc: 0.8224\n22850/40000 [================&gt;.............] - ETA: 1s - loss: 0.5212 - acc: 0.8224\n23750/40000 [================&gt;.............] - ETA: 0s - loss: 0.5215 - acc: 0.8221\n24650/40000 [=================&gt;............] - ETA: 0s - loss: 0.5234 - acc: 0.8213\n25500/40000 [==================&gt;...........] - ETA: 0s - loss: 0.5238 - acc: 0.8211\n26400/40000 [==================&gt;...........] - ETA: 0s - loss: 0.5240 - acc: 0.8208\n27000/40000 [===================&gt;..........] - ETA: 0s - loss: 0.5245 - acc: 0.8207\n27850/40000 [===================&gt;..........] - ETA: 0s - loss: 0.5255 - acc: 0.8202\n28800/40000 [====================&gt;.........] - ETA: 0s - loss: 0.5274 - acc: 0.8197\n29700/40000 [=====================&gt;........] - ETA: 0s - loss: 0.5269 - acc: 0.8200\n30600/40000 [=====================&gt;........] - ETA: 0s - loss: 0.5284 - acc: 0.8198\n31500/40000 [======================&gt;.......] - ETA: 0s - loss: 0.5286 - acc: 0.8197\n32000/40000 [=======================&gt;......] - ETA: 0s - loss: 0.5288 - acc: 0.8195\n32850/40000 [=======================&gt;......] - ETA: 0s - loss: 0.5309 - acc: 0.8190\n33750/40000 [========================&gt;.....] - ETA: 0s - loss: 0.5313 - acc: 0.8192\n34550/40000 [========================&gt;.....] - ETA: 0s - loss: 0.5318 - acc: 0.8191\n35400/40000 [=========================&gt;....] - ETA: 0s - loss: 0.5340 - acc: 0.8187\n36300/40000 [==========================&gt;...] - ETA: 0s - loss: 0.5349 - acc: 0.8186\n37150/40000 [==========================&gt;...] - ETA: 0s - loss: 0.5355 - acc: 0.8184\n38050/40000 [===========================&gt;..] - ETA: 0s - loss: 0.5370 - acc: 0.8179\n38950/40000 [============================&gt;.] - ETA: 0s - loss: 0.5383 - acc: 0.8174\n39850/40000 [============================&gt;.] - ETA: 0s - loss: 0.5394 - acc: 0.8169\n40000/40000 [==============================] - 3s 72us/step - loss: 0.5393 - acc: 0.8170 - val_loss: 1.5054 - val_acc: 0.6366\n\nEpoch 00015: val_loss did not improve from 1.06947\nEpoch 16/20\n\n   50/40000 [..............................] - ETA: 3s - loss: 0.3739 - acc: 0.9200\n  850/40000 [..............................] - ETA: 2s - loss: 0.4837 - acc: 0.8365\n 1700/40000 [&gt;.............................] - ETA: 2s - loss: 0.4872 - acc: 0.8376\n 2500/40000 [&gt;.............................] - ETA: 2s - loss: 0.4660 - acc: 0.8428\n 3400/40000 [=&gt;............................] - ETA: 2s - loss: 0.4684 - acc: 0.8406\n 4250/40000 [==&gt;...........................] - ETA: 2s - loss: 0.4620 - acc: 0.8405\n 5000/40000 [==&gt;...........................] - ETA: 2s - loss: 0.4575 - acc: 0.8408\n 5850/40000 [===&gt;..........................] - ETA: 2s - loss: 0.4617 - acc: 0.8402\n 6650/40000 [===&gt;..........................] - ETA: 2s - loss: 0.4663 - acc: 0.8376\n 7550/40000 [====&gt;.........................] - ETA: 2s - loss: 0.4714 - acc: 0.8376\n 8450/40000 [=====&gt;........................] - ETA: 1s - loss: 0.4695 - acc: 0.8376\n 9350/40000 [======&gt;.......................] - ETA: 1s - loss: 0.4707 - acc: 0.8385\n10150/40000 [======&gt;.......................] - ETA: 1s - loss: 0.4711 - acc: 0.8400\n11050/40000 [=======&gt;......................] - ETA: 1s - loss: 0.4766 - acc: 0.8371\n11800/40000 [=======&gt;......................] - ETA: 1s - loss: 0.4825 - acc: 0.8361\n12700/40000 [========&gt;.....................] - ETA: 1s - loss: 0.4883 - acc: 0.8339\n13550/40000 [=========&gt;....................] - ETA: 1s - loss: 0.4902 - acc: 0.8335\n14450/40000 [=========&gt;....................] - ETA: 1s - loss: 0.4926 - acc: 0.8325\n15350/40000 [==========&gt;...................] - ETA: 1s - loss: 0.4971 - acc: 0.8302\n16200/40000 [===========&gt;..................] - ETA: 1s - loss: 0.4974 - acc: 0.8297\n17100/40000 [===========&gt;..................] - ETA: 1s - loss: 0.4959 - acc: 0.8305\n18000/40000 [============&gt;.................] - ETA: 1s - loss: 0.5011 - acc: 0.8297\n18800/40000 [=============&gt;................] - ETA: 1s - loss: 0.5011 - acc: 0.8293\n19600/40000 [=============&gt;................] - ETA: 1s - loss: 0.5040 - acc: 0.8282\n20250/40000 [==============&gt;...............] - ETA: 1s - loss: 0.5051 - acc: 0.8274\n21150/40000 [==============&gt;...............] - ETA: 1s - loss: 0.5062 - acc: 0.8265\n21900/40000 [===============&gt;..............] - ETA: 1s - loss: 0.5068 - acc: 0.8263\n22750/40000 [================&gt;.............] - ETA: 1s - loss: 0.5075 - acc: 0.8258\n23550/40000 [================&gt;.............] - ETA: 1s - loss: 0.5098 - acc: 0.8249\n24450/40000 [=================&gt;............] - ETA: 0s - loss: 0.5086 - acc: 0.8249\n25350/40000 [==================&gt;...........] - ETA: 0s - loss: 0.5089 - acc: 0.8243\n25900/40000 [==================&gt;...........] - ETA: 0s - loss: 0.5093 - acc: 0.8241\n26800/40000 [===================&gt;..........] - ETA: 0s - loss: 0.5100 - acc: 0.8243\n27650/40000 [===================&gt;..........] - ETA: 0s - loss: 0.5101 - acc: 0.8239\n28300/40000 [====================&gt;.........] - ETA: 0s - loss: 0.5097 - acc: 0.8243\n29200/40000 [====================&gt;.........] - ETA: 0s - loss: 0.5095 - acc: 0.8246\n30050/40000 [=====================&gt;........] - ETA: 0s - loss: 0.5105 - acc: 0.8241\n30850/40000 [======================&gt;.......] - ETA: 0s - loss: 0.5116 - acc: 0.8239\n31650/40000 [======================&gt;.......] - ETA: 0s - loss: 0.5141 - acc: 0.8231\n32500/40000 [=======================&gt;......] - ETA: 0s - loss: 0.5156 - acc: 0.8229\n33400/40000 [========================&gt;.....] - ETA: 0s - loss: 0.5158 - acc: 0.8230\n34300/40000 [========================&gt;.....] - ETA: 0s - loss: 0.5163 - acc: 0.8229\n35200/40000 [=========================&gt;....] - ETA: 0s - loss: 0.5168 - acc: 0.8229\n36100/40000 [==========================&gt;...] - ETA: 0s - loss: 0.5196 - acc: 0.8221\n36750/40000 [==========================&gt;...] - ETA: 0s - loss: 0.5186 - acc: 0.8221\n37500/40000 [===========================&gt;..] - ETA: 0s - loss: 0.5192 - acc: 0.8220\n38350/40000 [===========================&gt;..] - ETA: 0s - loss: 0.5199 - acc: 0.8218\n39250/40000 [============================&gt;.] - ETA: 0s - loss: 0.5204 - acc: 0.8216\n40000/40000 [==============================] - 3s 72us/step - loss: 0.5214 - acc: 0.8213 - val_loss: 1.6005 - val_acc: 0.6290\n\nEpoch 00016: val_loss did not improve from 1.06947\nEpoch 17/20\n\n   50/40000 [..............................] - ETA: 3s - loss: 0.4140 - acc: 0.8200\n  900/40000 [..............................] - ETA: 2s - loss: 0.4414 - acc: 0.8433\n 1750/40000 [&gt;.............................] - ETA: 2s - loss: 0.4532 - acc: 0.8411\n 2600/40000 [&gt;.............................] - ETA: 2s - loss: 0.4629 - acc: 0.8354\n 3450/40000 [=&gt;............................] - ETA: 2s - loss: 0.4774 - acc: 0.8336\n 4200/40000 [==&gt;...........................] - ETA: 2s - loss: 0.4765 - acc: 0.8333\n 5150/40000 [==&gt;...........................] - ETA: 2s - loss: 0.4675 - acc: 0.8369\n 6100/40000 [===&gt;..........................] - ETA: 2s - loss: 0.4678 - acc: 0.8379\n 7000/40000 [====&gt;.........................] - ETA: 1s - loss: 0.4734 - acc: 0.8369\n 7900/40000 [====&gt;.........................] - ETA: 1s - loss: 0.4759 - acc: 0.8358\n 8750/40000 [=====&gt;........................] - ETA: 1s - loss: 0.4751 - acc: 0.8358\n 9650/40000 [======&gt;.......................] - ETA: 1s - loss: 0.4767 - acc: 0.8345\n10550/40000 [======&gt;.......................] - ETA: 1s - loss: 0.4765 - acc: 0.8348\n11450/40000 [=======&gt;......................] - ETA: 1s - loss: 0.4796 - acc: 0.8332\n12300/40000 [========&gt;.....................] - ETA: 1s - loss: 0.4810 - acc: 0.8329\n13150/40000 [========&gt;.....................] - ETA: 1s - loss: 0.4815 - acc: 0.8322\n14050/40000 [=========&gt;....................] - ETA: 1s - loss: 0.4819 - acc: 0.8320\n14850/40000 [==========&gt;...................] - ETA: 1s - loss: 0.4820 - acc: 0.8314\n15750/40000 [==========&gt;...................] - ETA: 1s - loss: 0.4844 - acc: 0.8309\n16600/40000 [===========&gt;..................] - ETA: 1s - loss: 0.4870 - acc: 0.8302\n17450/40000 [============&gt;.................] - ETA: 1s - loss: 0.4856 - acc: 0.8311\n18300/40000 [============&gt;.................] - ETA: 1s - loss: 0.4868 - acc: 0.8312\n19150/40000 [=============&gt;................] - ETA: 1s - loss: 0.4869 - acc: 0.8319\n19900/40000 [=============&gt;................] - ETA: 1s - loss: 0.4889 - acc: 0.8309\n20800/40000 [==============&gt;...............] - ETA: 1s - loss: 0.4918 - acc: 0.8300\n21700/40000 [===============&gt;..............] - ETA: 1s - loss: 0.4924 - acc: 0.8295\n22550/40000 [===============&gt;..............] - ETA: 1s - loss: 0.4910 - acc: 0.8304\n23000/40000 [================&gt;.............] - ETA: 1s - loss: 0.4888 - acc: 0.8311\n23800/40000 [================&gt;.............] - ETA: 0s - loss: 0.4914 - acc: 0.8303\n24750/40000 [=================&gt;............] - ETA: 0s - loss: 0.4952 - acc: 0.8297\n25650/40000 [==================&gt;...........] - ETA: 0s - loss: 0.4961 - acc: 0.8296\n26450/40000 [==================&gt;...........] - ETA: 0s - loss: 0.4969 - acc: 0.8293\n27300/40000 [===================&gt;..........] - ETA: 0s - loss: 0.4978 - acc: 0.8288\n28200/40000 [====================&gt;.........] - ETA: 0s - loss: 0.4972 - acc: 0.8292\n29050/40000 [====================&gt;.........] - ETA: 0s - loss: 0.4984 - acc: 0.8289\n29750/40000 [=====================&gt;........] - ETA: 0s - loss: 0.5003 - acc: 0.8287\n30550/40000 [=====================&gt;........] - ETA: 0s - loss: 0.5026 - acc: 0.8277\n31350/40000 [======================&gt;.......] - ETA: 0s - loss: 0.5037 - acc: 0.8273\n32250/40000 [=======================&gt;......] - ETA: 0s - loss: 0.5016 - acc: 0.8278\n33150/40000 [=======================&gt;......] - ETA: 0s - loss: 0.5032 - acc: 0.8267\n34000/40000 [========================&gt;.....] - ETA: 0s - loss: 0.5030 - acc: 0.8266\n34850/40000 [=========================&gt;....] - ETA: 0s - loss: 0.5037 - acc: 0.8268\n35750/40000 [=========================&gt;....] - ETA: 0s - loss: 0.5057 - acc: 0.8260\n36550/40000 [==========================&gt;...] - ETA: 0s - loss: 0.5068 - acc: 0.8256\n37350/40000 [===========================&gt;..] - ETA: 0s - loss: 0.5069 - acc: 0.8257\n38250/40000 [===========================&gt;..] - ETA: 0s - loss: 0.5078 - acc: 0.8249\n39150/40000 [============================&gt;.] - ETA: 0s - loss: 0.5080 - acc: 0.8249\n40000/40000 [==============================] - 3s 70us/step - loss: 0.5083 - acc: 0.8247 - val_loss: 1.6807 - val_acc: 0.6210\n\nEpoch 00017: val_loss did not improve from 1.06947\nEpoch 18/20\n\n   50/40000 [..............................] - ETA: 4s - loss: 0.4196 - acc: 0.8600\n  900/40000 [..............................] - ETA: 2s - loss: 0.4490 - acc: 0.8422\n 1750/40000 [&gt;.............................] - ETA: 2s - loss: 0.4479 - acc: 0.8417\n 2650/40000 [&gt;.............................] - ETA: 2s - loss: 0.4347 - acc: 0.8509\n 3500/40000 [=&gt;............................] - ETA: 2s - loss: 0.4383 - acc: 0.8454\n 4400/40000 [==&gt;...........................] - ETA: 2s - loss: 0.4393 - acc: 0.8441\n 5300/40000 [==&gt;...........................] - ETA: 2s - loss: 0.4495 - acc: 0.8438\n 6100/40000 [===&gt;..........................] - ETA: 2s - loss: 0.4475 - acc: 0.8430\n 7000/40000 [====&gt;.........................] - ETA: 1s - loss: 0.4523 - acc: 0.8430\n 7900/40000 [====&gt;.........................] - ETA: 1s - loss: 0.4502 - acc: 0.8434\n 8800/40000 [=====&gt;........................] - ETA: 1s - loss: 0.4501 - acc: 0.8451\n 9250/40000 [=====&gt;........................] - ETA: 1s - loss: 0.4515 - acc: 0.8454\n 9450/40000 [======&gt;.......................] - ETA: 2s - loss: 0.4507 - acc: 0.8459\n10350/40000 [======&gt;.......................] - ETA: 1s - loss: 0.4541 - acc: 0.8452\n11250/40000 [=======&gt;......................] - ETA: 1s - loss: 0.4581 - acc: 0.8428\n12150/40000 [========&gt;.....................] - ETA: 1s - loss: 0.4634 - acc: 0.8403\n13100/40000 [========&gt;.....................] - ETA: 1s - loss: 0.4610 - acc: 0.8407\n13850/40000 [=========&gt;....................] - ETA: 1s - loss: 0.4621 - acc: 0.8403\n14450/40000 [=========&gt;....................] - ETA: 1s - loss: 0.4627 - acc: 0.8397\n15100/40000 [==========&gt;...................] - ETA: 1s - loss: 0.4647 - acc: 0.8391\n16050/40000 [===========&gt;..................] - ETA: 1s - loss: 0.4627 - acc: 0.8399\n16950/40000 [===========&gt;..................] - ETA: 1s - loss: 0.4644 - acc: 0.8395\n17900/40000 [============&gt;.................] - ETA: 1s - loss: 0.4663 - acc: 0.8389\n18850/40000 [=============&gt;................] - ETA: 1s - loss: 0.4682 - acc: 0.8386\n19650/40000 [=============&gt;................] - ETA: 1s - loss: 0.4695 - acc: 0.8377\n20550/40000 [==============&gt;...............] - ETA: 1s - loss: 0.4737 - acc: 0.8358\n21400/40000 [===============&gt;..............] - ETA: 1s - loss: 0.4735 - acc: 0.8358\n22250/40000 [===============&gt;..............] - ETA: 1s - loss: 0.4737 - acc: 0.8361\n23000/40000 [================&gt;.............] - ETA: 1s - loss: 0.4747 - acc: 0.8358\n23800/40000 [================&gt;.............] - ETA: 1s - loss: 0.4768 - acc: 0.8352\n24650/40000 [=================&gt;............] - ETA: 0s - loss: 0.4780 - acc: 0.8345\n25050/40000 [=================&gt;............] - ETA: 1s - loss: 0.4788 - acc: 0.8345\n25900/40000 [==================&gt;...........] - ETA: 0s - loss: 0.4775 - acc: 0.8348\n26600/40000 [==================&gt;...........] - ETA: 0s - loss: 0.4803 - acc: 0.8338\n27100/40000 [===================&gt;..........] - ETA: 0s - loss: 0.4805 - acc: 0.8339\n27650/40000 [===================&gt;..........] - ETA: 0s - loss: 0.4813 - acc: 0.8335\n28450/40000 [====================&gt;.........] - ETA: 0s - loss: 0.4846 - acc: 0.8323\n29150/40000 [====================&gt;.........] - ETA: 0s - loss: 0.4857 - acc: 0.8322\n29900/40000 [=====================&gt;........] - ETA: 0s - loss: 0.4848 - acc: 0.8324\n30750/40000 [======================&gt;.......] - ETA: 0s - loss: 0.4851 - acc: 0.8327\n31700/40000 [======================&gt;.......] - ETA: 0s - loss: 0.4862 - acc: 0.8322\n32650/40000 [=======================&gt;......] - ETA: 0s - loss: 0.4870 - acc: 0.8319\n33550/40000 [========================&gt;.....] - ETA: 0s - loss: 0.4870 - acc: 0.8319\n34450/40000 [========================&gt;.....] - ETA: 0s - loss: 0.4888 - acc: 0.8315\n35400/40000 [=========================&gt;....] - ETA: 0s - loss: 0.4896 - acc: 0.8310\n36150/40000 [==========================&gt;...] - ETA: 0s - loss: 0.4911 - acc: 0.8307\n36900/40000 [==========================&gt;...] - ETA: 0s - loss: 0.4915 - acc: 0.8305\n37800/40000 [===========================&gt;..] - ETA: 0s - loss: 0.4920 - acc: 0.8302\n38700/40000 [============================&gt;.] - ETA: 0s - loss: 0.4945 - acc: 0.8297\n39550/40000 [============================&gt;.] - ETA: 0s - loss: 0.4944 - acc: 0.8297\n40000/40000 [==============================] - 3s 76us/step - loss: 0.4944 - acc: 0.8296 - val_loss: 1.7350 - val_acc: 0.6218\n\nEpoch 00018: val_loss did not improve from 1.06947\nEpoch 19/20\n\n   50/40000 [..............................] - ETA: 3s - loss: 0.4712 - acc: 0.8200\n  900/40000 [..............................] - ETA: 2s - loss: 0.4537 - acc: 0.8378\n 1750/40000 [&gt;.............................] - ETA: 2s - loss: 0.4674 - acc: 0.8343\n 2650/40000 [&gt;.............................] - ETA: 2s - loss: 0.4596 - acc: 0.8389\n 3500/40000 [=&gt;............................] - ETA: 2s - loss: 0.4471 - acc: 0.8437\n 4350/40000 [==&gt;...........................] - ETA: 2s - loss: 0.4372 - acc: 0.8453\n 5150/40000 [==&gt;...........................] - ETA: 2s - loss: 0.4364 - acc: 0.8474\n 5900/40000 [===&gt;..........................] - ETA: 2s - loss: 0.4404 - acc: 0.8454\n 6850/40000 [====&gt;.........................] - ETA: 2s - loss: 0.4341 - acc: 0.8488\n 7750/40000 [====&gt;.........................] - ETA: 1s - loss: 0.4378 - acc: 0.8488\n 8650/40000 [=====&gt;........................] - ETA: 1s - loss: 0.4455 - acc: 0.8481\n 9500/40000 [======&gt;.......................] - ETA: 1s - loss: 0.4476 - acc: 0.8478\n10400/40000 [======&gt;.......................] - ETA: 1s - loss: 0.4502 - acc: 0.8468\n11300/40000 [=======&gt;......................] - ETA: 1s - loss: 0.4539 - acc: 0.8457\n12200/40000 [========&gt;.....................] - ETA: 1s - loss: 0.4523 - acc: 0.8461\n13000/40000 [========&gt;.....................] - ETA: 1s - loss: 0.4512 - acc: 0.8462\n13850/40000 [=========&gt;....................] - ETA: 1s - loss: 0.4535 - acc: 0.8445\n14750/40000 [==========&gt;...................] - ETA: 1s - loss: 0.4547 - acc: 0.8435\n15650/40000 [==========&gt;...................] - ETA: 1s - loss: 0.4543 - acc: 0.8436\n16300/40000 [===========&gt;..................] - ETA: 1s - loss: 0.4540 - acc: 0.8435\n17200/40000 [===========&gt;..................] - ETA: 1s - loss: 0.4517 - acc: 0.8451\n18100/40000 [============&gt;.................] - ETA: 1s - loss: 0.4542 - acc: 0.8448\n18550/40000 [============&gt;.................] - ETA: 1s - loss: 0.4550 - acc: 0.8447\n19500/40000 [=============&gt;................] - ETA: 1s - loss: 0.4573 - acc: 0.8442\n20400/40000 [==============&gt;...............] - ETA: 1s - loss: 0.4579 - acc: 0.8436\n21250/40000 [==============&gt;...............] - ETA: 1s - loss: 0.4592 - acc: 0.8434\n22050/40000 [===============&gt;..............] - ETA: 1s - loss: 0.4623 - acc: 0.8427\n22950/40000 [================&gt;.............] - ETA: 1s - loss: 0.4623 - acc: 0.8420\n23850/40000 [================&gt;.............] - ETA: 0s - loss: 0.4648 - acc: 0.8409\n24750/40000 [=================&gt;............] - ETA: 0s - loss: 0.4644 - acc: 0.8408\n25550/40000 [==================&gt;...........] - ETA: 0s - loss: 0.4651 - acc: 0.8404\n26300/40000 [==================&gt;...........] - ETA: 0s - loss: 0.4643 - acc: 0.8403\n27250/40000 [===================&gt;..........] - ETA: 0s - loss: 0.4657 - acc: 0.8400\n28200/40000 [====================&gt;.........] - ETA: 0s - loss: 0.4641 - acc: 0.8403\n29050/40000 [====================&gt;.........] - ETA: 0s - loss: 0.4662 - acc: 0.8399\n29900/40000 [=====================&gt;........] - ETA: 0s - loss: 0.4664 - acc: 0.8396\n30800/40000 [======================&gt;.......] - ETA: 0s - loss: 0.4681 - acc: 0.8390\n31700/40000 [======================&gt;.......] - ETA: 0s - loss: 0.4694 - acc: 0.8385\n32600/40000 [=======================&gt;......] - ETA: 0s - loss: 0.4726 - acc: 0.8375\n33450/40000 [========================&gt;.....] - ETA: 0s - loss: 0.4727 - acc: 0.8375\n33900/40000 [========================&gt;.....] - ETA: 0s - loss: 0.4730 - acc: 0.8375\n34800/40000 [=========================&gt;....] - ETA: 0s - loss: 0.4746 - acc: 0.8371\n35700/40000 [=========================&gt;....] - ETA: 0s - loss: 0.4733 - acc: 0.8375\n36600/40000 [==========================&gt;...] - ETA: 0s - loss: 0.4744 - acc: 0.8368\n37500/40000 [===========================&gt;..] - ETA: 0s - loss: 0.4746 - acc: 0.8372\n38400/40000 [===========================&gt;..] - ETA: 0s - loss: 0.4761 - acc: 0.8368\n39300/40000 [============================&gt;.] - ETA: 0s - loss: 0.4769 - acc: 0.8365\n40000/40000 [==============================] - 3s 70us/step - loss: 0.4780 - acc: 0.8362 - val_loss: 1.7377 - val_acc: 0.6249\n\nEpoch 00019: val_loss did not improve from 1.06947\nEpoch 20/20\n\n   50/40000 [..............................] - ETA: 3s - loss: 0.2990 - acc: 0.9200\n  950/40000 [..............................] - ETA: 2s - loss: 0.3963 - acc: 0.8842\n 1850/40000 [&gt;.............................] - ETA: 2s - loss: 0.4057 - acc: 0.8708\n 2650/40000 [&gt;.............................] - ETA: 2s - loss: 0.4161 - acc: 0.8672\n 3500/40000 [=&gt;............................] - ETA: 2s - loss: 0.4189 - acc: 0.8611\n 4200/40000 [==&gt;...........................] - ETA: 2s - loss: 0.4133 - acc: 0.8624\n 4950/40000 [==&gt;...........................] - ETA: 2s - loss: 0.4031 - acc: 0.8659\n 5850/40000 [===&gt;..........................] - ETA: 2s - loss: 0.4037 - acc: 0.8638\n 6750/40000 [====&gt;.........................] - ETA: 2s - loss: 0.4101 - acc: 0.8606\n 7650/40000 [====&gt;.........................] - ETA: 1s - loss: 0.4206 - acc: 0.8561\n 8550/40000 [=====&gt;........................] - ETA: 1s - loss: 0.4227 - acc: 0.8553\n 9300/40000 [=====&gt;........................] - ETA: 1s - loss: 0.4234 - acc: 0.8539\n10200/40000 [======&gt;.......................] - ETA: 1s - loss: 0.4238 - acc: 0.8537\n11100/40000 [=======&gt;......................] - ETA: 1s - loss: 0.4259 - acc: 0.8527\n12000/40000 [========&gt;.....................] - ETA: 1s - loss: 0.4294 - acc: 0.8523\n12750/40000 [========&gt;.....................] - ETA: 1s - loss: 0.4311 - acc: 0.8518\n13550/40000 [=========&gt;....................] - ETA: 1s - loss: 0.4327 - acc: 0.8513\n14450/40000 [=========&gt;....................] - ETA: 1s - loss: 0.4380 - acc: 0.8499\n15200/40000 [==========&gt;...................] - ETA: 1s - loss: 0.4389 - acc: 0.8493\n16100/40000 [===========&gt;..................] - ETA: 1s - loss: 0.4387 - acc: 0.8492\n16950/40000 [===========&gt;..................] - ETA: 1s - loss: 0.4385 - acc: 0.8490\n17750/40000 [============&gt;.................] - ETA: 1s - loss: 0.4406 - acc: 0.8480\n18700/40000 [=============&gt;................] - ETA: 1s - loss: 0.4401 - acc: 0.8486\n19500/40000 [=============&gt;................] - ETA: 1s - loss: 0.4425 - acc: 0.8482\n20400/40000 [==============&gt;...............] - ETA: 1s - loss: 0.4454 - acc: 0.8479\n21350/40000 [===============&gt;..............] - ETA: 1s - loss: 0.4476 - acc: 0.8468\n21450/40000 [===============&gt;..............] - ETA: 1s - loss: 0.4477 - acc: 0.8466\n21950/40000 [===============&gt;..............] - ETA: 1s - loss: 0.4472 - acc: 0.8467\n22800/40000 [================&gt;.............] - ETA: 1s - loss: 0.4478 - acc: 0.8463\n23600/40000 [================&gt;.............] - ETA: 1s - loss: 0.4505 - acc: 0.8456\n24500/40000 [=================&gt;............] - ETA: 0s - loss: 0.4526 - acc: 0.8453\n25350/40000 [==================&gt;...........] - ETA: 0s - loss: 0.4550 - acc: 0.8446\n26300/40000 [==================&gt;...........] - ETA: 0s - loss: 0.4567 - acc: 0.8434\n27150/40000 [===================&gt;..........] - ETA: 0s - loss: 0.4575 - acc: 0.8428\n28000/40000 [====================&gt;.........] - ETA: 0s - loss: 0.4587 - acc: 0.8424\n28800/40000 [====================&gt;.........] - ETA: 0s - loss: 0.4596 - acc: 0.8423\n29750/40000 [=====================&gt;........] - ETA: 0s - loss: 0.4637 - acc: 0.8411\n30650/40000 [=====================&gt;........] - ETA: 0s - loss: 0.4640 - acc: 0.8409\n31550/40000 [======================&gt;.......] - ETA: 0s - loss: 0.4640 - acc: 0.8406\n32400/40000 [=======================&gt;......] - ETA: 0s - loss: 0.4664 - acc: 0.8395\n33300/40000 [=======================&gt;......] - ETA: 0s - loss: 0.4671 - acc: 0.8393\n34150/40000 [========================&gt;.....] - ETA: 0s - loss: 0.4670 - acc: 0.8393\n35000/40000 [=========================&gt;....] - ETA: 0s - loss: 0.4680 - acc: 0.8391\n35850/40000 [=========================&gt;....] - ETA: 0s - loss: 0.4677 - acc: 0.8391\n36650/40000 [==========================&gt;...] - ETA: 0s - loss: 0.4674 - acc: 0.8391\n37300/40000 [==========================&gt;...] - ETA: 0s - loss: 0.4674 - acc: 0.8390\n37700/40000 [===========================&gt;..] - ETA: 0s - loss: 0.4684 - acc: 0.8390\n38000/40000 [===========================&gt;..] - ETA: 0s - loss: 0.4678 - acc: 0.8391\n38850/40000 [============================&gt;.] - ETA: 0s - loss: 0.4677 - acc: 0.8390\n39300/40000 [============================&gt;.] - ETA: 0s - loss: 0.4685 - acc: 0.8388\n40000/40000 [==============================] - 3s 75us/step - loss: 0.4685 - acc: 0.8387 - val_loss: 1.8427 - val_acc: 0.6196\n\nEpoch 00020: val_loss did not improve from 1.06947\nOut[8]: &lt;keras.callbacks.History at 0x7fba56f80d30&gt;</div>"]}}],"execution_count":9},{"cell_type":"code","source":["my_ResNet50_model.load_weights('weights.best.CifarResNet-50.hdf5')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["my_ResNet50_predictions = [np.argmax(my_ResNet50_model.predict(np.expand_dims(feature, axis=0))) for feature in test_ResNet50]\n\n# report test accuracy\ntest_accuracy = 100*np.sum(np.array(my_ResNet50_predictions)==np.argmax(test_targets, axis=1))/len(my_ResNet50_predictions)\nprint('Test accuracy: %.4f%%' % test_accuracy)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test accuracy: 64.2600%\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["import mlflow.keras\nmlflow.keras.save_model(my_ResNet50_model, '/dbfs/mnt/cifar-10-batches-py/saved_model/cifar10_resnet50')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"code","source":["import requests\nimport json\nimg = open('/dbfs/mnt/dogImages/dogImages/test/134.Shiba_inu/Capture.PNG', 'rb').read()\nheaders = {'Content-Type':'application/json'}\n\nresp = requests.post('http://1f770b22-8329-4656-b1c6-5ac11e462c30.eastus.azurecontainer.io/score',data=img, headers=headers, timeout=300)\njson.loads(resp.json())['predicted_label']"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[13]: &#39;MEDIUM_MAMMALS&#39;</div>"]}}],"execution_count":13},{"cell_type":"code","source":["test_ResNet50"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[14]: array([[[[-0.       , -0.       , -0.       , ..., -0.       ,\n          -0.       , -0.       ]]],\n\n\n       [[[-0.       , -0.       , -0.       , ..., -0.       ,\n          -0.       , -0.       ]]],\n\n\n       [[[-0.       , -0.       , -0.       , ..., -0.       ,\n          -0.       , -0.       ]]],\n\n\n       ...,\n\n\n       [[[-0.       , -0.       , -0.       , ..., -0.       ,\n          -0.       , -0.       ]]],\n\n\n       [[[-0.       , -0.       ,  7.638767 , ...,  5.11226  ,\n          -0.       , -0.       ]]],\n\n\n       [[[-0.       , -0.       , -0.       , ...,  0.8227267,\n          -0.       , -0.       ]]]], dtype=float32)</div>"]}}],"execution_count":14},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":15}],"metadata":{"name":"cifar_classification","notebookId":949048213614855},"nbformat":4,"nbformat_minor":0}
